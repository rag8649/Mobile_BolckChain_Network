package consumer

import (
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"log"
	"strconv"
	"sync"
	"time"

	"github.com/cosmos/cosmos-sdk/fullnode_bridge/tx"
	"github.com/cosmos/cosmos-sdk/fullnode_bridge/types"

	"github.com/cosmos/cosmos-sdk/fullnode_bridge/config"

	"github.com/IBM/sarama"

	"crypto/sha256"

	"github.com/btcsuite/btcutil/bech32"
	"golang.org/x/crypto/ripemd160"
)

type lightTxHandler struct{}

type SignatureEntry struct {
	TxMsg     types.LightTxMessage
	Address   string
	Timestamp time.Time
}

var (
	VoteMap   = make(map[string][]SignatureEntry) // hash -> ì„œëª…ì ëª©ë¡
	DeviceID  = make(map[string]string)           // hash -> device_id
	VoteMutex sync.Mutex
)

var (
	VoteMemberCount int // ë°ì´í„°ë² ì´ìŠ¤ ë©¤ë²„ ìˆ˜ ê¸°ë¡ ë³€ìˆ˜
)

var SentLatLng = make(map[string]bool) // ì¤‘ë³µ ì „ì†¡ ë°©ì§€ìš©
var RewardWeight = make(map[string]float64)
var KafkaProducerLatLng sarama.SyncProducer // ìœ„ë„ê²½ë„ ì „ì†¡ìš© í”„ë¡œë“€ì„œ

type Location struct { // ì˜¤ë¼í´ì— ì „ë‹¬í•˜ëŠ” ìœ„ì¹˜ ê°’
	Latitude  float64 `json:"latitude"`
	Longitude float64 `json:"longitude"`
}

type LocationOutputMessage struct { // ì˜¤ë¼í´ë¡œë¶€í„° ë°›ëŠ” ê²°ê³¼ê°’
	Hash     string  `json:"hash"`
	Output   float64 `json:"output"`
	SenderID string  `json:"sender_id"`
}

type VoteMemberMsg struct {
	Count int `json:"count"`
}

var KafkaProducerDevice sarama.SyncProducer // ë””ë°”ì´ìŠ¤ ì •ë³´ ì „ì†¡ í”„ë¡œë“€ì„œ

func InitDeviceProducer() {
	KafkaProducerDevice = NewKafkaSyncProducer(config.KafkaBrokers)
	KafkaProducerLatLng = NewKafkaSyncProducer(config.KafkaBrokers)
}

func NewKafkaSyncProducer(brokers []string) sarama.SyncProducer { // í”„ë¡œë“€ì„œ ì´ˆê¸°í™”
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Retry.Max = 5
	config.Producer.Return.Successes = true

	producer, err := sarama.NewSyncProducer(brokers, config)
	if err != nil {
		log.Fatalf("Kafka í”„ë¡œë“€ì„œ ìƒì„± ì‹¤íŒ¨: %v", err)
	}
	return producer
}

func (h *lightTxHandler) Setup(_ sarama.ConsumerGroupSession) error   { return nil }
func (h *lightTxHandler) Cleanup(_ sarama.ConsumerGroupSession) error { return nil }

func (h *lightTxHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error { // íƒœì–‘ê´‘ ë°ì´í„° ìˆ˜ì‹  ì²˜ë¦¬
	for msg := range claim.Messages() {
		fmt.Println("[Kafka: Solar data][Raw Message]:", string(msg.Value)) // ğŸ‘‰ ìˆ˜ì‹ ëœ ì›ë³¸ ë©”ì‹œì§€ ì¶œë ¥

		var txMsg types.LightTxMessage
		if err := json.Unmarshal(msg.Value, &txMsg); err != nil {
			fmt.Println("[Kafka: Solar data] ë©”ì‹œì§€ íŒŒì‹± ì‹¤íŒ¨:", err)
			continue
		}

		for len(txMsg.Pubkey)%4 != 0 {
			txMsg.Pubkey += "="
		}
		pubkeyBytes, err := base64.StdEncoding.DecodeString(txMsg.Pubkey)
		if err != nil {
			fmt.Println("[Kafka: Solar data] í¼ë¸”ë¦­í‚¤ ë””ì½”ë”© ì‹¤íŒ¨:", err)
			continue
		}

		if len(pubkeyBytes) != 33 {
			fmt.Println("[Kafka: Solar data] ì˜ëª»ëœ í¼ë¸”ë¦­í‚¤ ê¸¸ì´:", len(pubkeyBytes))
			continue
		}

		address, err := PubKeyToAddress(pubkeyBytes)
		if err != nil {
			fmt.Println("[Kafka: Solar data] ì£¼ì†Œ ìƒì„± ì‹¤íŒ¨:", err)
			continue
		}

		if !SentLatLng[txMsg.Hash] {
			var location Location
			if txMsg.Original != nil {
				location = Location{
					Latitude:  txMsg.Original.Location.Latitude,
					Longitude: txMsg.Original.Location.Longitude,
				}
			}

			// ìœ„ë„/ê²½ë„ê°€ ëª¨ë‘ 0ì´ ì•„ë‹ˆì–´ì•¼ ì „ì†¡
			if location.Latitude != 0 && location.Longitude != 0 {
				sendLocationToKafka(txMsg.Hash, location, config.FullnodeID)
				SentLatLng[txMsg.Hash] = true
			} else {
				fmt.Println("âš ï¸ ìœ„ë„/ê²½ë„ ì •ë³´ ì—†ìŒ ë˜ëŠ” 0, Kafka ì „ì†¡ ìƒëµ:", txMsg.Hash)
			}
		}

		VoteMutex.Lock()
		VoteMap[txMsg.Hash] = append(VoteMap[txMsg.Hash], SignatureEntry{
			TxMsg:     txMsg,
			Address:   address,
			Timestamp: time.Now(),
		})
		// í•´ì‹œë³„ë¡œ device_id ë˜ëŠ” facility_id ì €ì¥

		if txMsg.Original != nil && txMsg.Original.DeviceID != "" {
			DeviceID[txMsg.Hash] = txMsg.Original.DeviceID
		} else if txMsg.REC != nil && txMsg.REC.FacilityID != "" {
			DeviceID[txMsg.Hash] = txMsg.REC.FacilityID
		} else {
			fmt.Println("[Kafka: Solar data] DeviceIDì™€ FacilityID ëª¨ë‘ ì¡´ì¬í•˜ì§€ ì•ŠìŒ, ì €ì¥ ì•ˆ í•¨:", txMsg.Hash)
		}
		VoteMutex.Unlock()

		session.MarkMessage(msg, "")
	}
	return nil
}

func PubKeyToAddress(pubKeyBytes []byte) (string, error) { // ì£¼ì†Œ ë³€í™˜ í•¨ìˆ˜
	// 1. SHA-256
	sha := sha256.Sum256(pubKeyBytes)

	// 2. RIPEMD-160
	ripemd := ripemd160.New()
	_, err := ripemd.Write(sha[:])
	if err != nil {
		return "", err
	}
	pubKeyHash := ripemd.Sum(nil) // 20ë°”ì´íŠ¸

	// 3. Bech32 ì¸ì½”ë”©
	converted, err := bech32.ConvertBits(pubKeyHash, 8, 5, true)
	if err != nil {
		return "", err
	}
	address, err := bech32.Encode("cosmos", converted)
	if err != nil {
		return "", err
	}

	return address, nil
}

// ìœ„ì¹˜ ì •ë³´ -> ì˜¤ë¼í´ ì „ì†¡
func sendLocationToKafka(hash string, loc Location, senderID string) {
	payload := map[string]interface{}{
		"hash":      hash,
		"location":  loc,
		"sender_id": senderID,
	}
	msgBytes, _ := json.Marshal(payload)

	_, _, err := KafkaProducerLatLng.SendMessage(&sarama.ProducerMessage{
		Topic: config.TopicLocationProducer,
		Value: sarama.ByteEncoder(msgBytes),
	})
	if err != nil {
		fmt.Println("[Kafka: Solar data] Location Kafka ì „ì†¡ ì‹¤íŒ¨:", err)
	} else {
		fmt.Println("[Kafka: Solar data] Location Kafka ì „ì†¡ ì„±ê³µ:", string(msgBytes))
	}
}

func VoteEvaluator() { // íˆ¬í‘œ ìˆ˜ì§‘ ë°˜ë³µ í•¨ìˆ˜

	ticker := time.NewTicker(10 * time.Second)
	go func() {
		for range ticker.C {
			now := time.Now()
			fmt.Println("[Kafka: Solar data] íˆ¬í‘œ ìˆ˜ì§‘ ì‹œì‘:", now.Format(time.RFC3339))

			VoteMutex.Lock()
			for hash, entries := range VoteMap {
				if len(entries) == 0 {
					fmt.Printf("[Kafka: Solar data] Tx: [%s] entries ì—†ìŒ. ê±´ë„ˆëœ€\n", hash)
					continue
				}

				elapsed := now.Sub(entries[0].Timestamp)
				fmt.Printf("[Kafka: Solar data]  [%s] entry ìˆ˜: %d, ê²½ê³¼ì‹œê°„: %.1fì´ˆ\n", hash, len(entries), elapsed.Seconds())

				if elapsed < 10*time.Second {
					fmt.Printf("[Kafka: Solar data] (%.1fì´ˆ ê²½ê³¼). íˆ¬í‘œ ê²€ì¦ ì¤‘\n", elapsed.Seconds())
					continue
				}

				// ì£¼ì†Œ ì¤‘ë³µ ì œê±°
				unique := map[string]bool{}
				for _, e := range entries {
					unique[e.Address] = true
				}
				var uniqueList []string
				for k := range unique {
					uniqueList = append(uniqueList, k)
				}

				if len(unique) >= 1 {
					// if len(unique) >= VoteMemberCount/2 {
					txMsg := entries[0].TxMsg
					fmt.Println("[Kafka: Solar data] íŠ¸ëœì­ì…˜ ì „ì†¡ ì‹œë„ ì¤‘...")

					txHash, err := tx.BroadcastLightTx(txMsg)
					if err != nil {
						fmt.Println("[Kafka: Solar data] íŠ¸ëœì­ì…˜ ì „ì†¡ ì‹¤íŒ¨:", err)
					} else {
						fmt.Printf("[Kafka: Solar data] íŠ¸ëœì­ì…˜ ì „ì†¡ ì„±ê³µ: %s\n", txHash)
						fmt.Printf("[Kafka: Solar data] â†’ ì„œëª…ì ì£¼ì†Œ ëª©ë¡: %v\n", uniqueList)

						deviceId := DeviceID[hash]
						if err := requestDeviceAddress(KafkaProducerDevice, deviceId); err != nil {
							fmt.Println("ì£¼ì†Œ ìš”ì²­ ì‹¤íŒ¨:", err)
						} else {
							// ì¼ì • ì‹œê°„ ëŒ€ê¸° (ìµœëŒ€ 1ì´ˆ)
							var userAddress string
							for i := 0; i < 20; i++ {
								if val, ok := deviceAddressMap.Load(deviceId); ok {
									userAddress = val.(string)
									break
								}
								time.Sleep(100 * time.Millisecond)
							}

							if txMsg.Original != nil {
								// ğŸŒ SolarData ê¸°ë°˜ ë³´ìƒ
								tx.SendRewardTx(userAddress, txMsg.Original.TotalEnergy+txMsg.Original.TotalEnergy*RewardWeight[txMsg.Hash])
							} else if txMsg.REC != nil {
								// REC ê¸°ë°˜ ë³´ìƒ: ì¸¡ì •ëŸ‰ MWhë¥¼ float64ë¡œ ë³€í™˜ í›„ ë³´ìƒ
								mwhStr := txMsg.REC.MeasuredVolumeMWh
								mwh, err := strconv.ParseFloat(mwhStr, 64)
								if err != nil {
									fmt.Printf("[Kafka: Solar data] REC ë°œì „ëŸ‰ íŒŒì‹± ì‹¤íŒ¨: %v\n", err)
								} else {
									// MWh â†’ Wh ë³€í™˜ (1 MWh = 1,000,000 Wh)
									tx.SendRewardTx(userAddress, mwh*1000000)
								}
							} else {
								fmt.Println("[Kafka: Solar data] ë³´ìƒí•  ë°ì´í„° ì—†ìŒ (Original, REC ëª¨ë‘ nil)")
							}
						}
					}

					delete(VoteMap, hash)
					SentLatLng[hash] = false
					RewardWeight[hash] = 1
					fmt.Printf("[Kafka: Solar data] [%s] voteMapì—ì„œ ì œê±°ë¨\n", hash)
				} else {
					fmt.Printf("[Kafka: Solar data] ê³ ìœ  ì£¼ì†Œ ì—†ìŒ. íŠ¸ëœì­ì…˜ ì „ì†¡ ì•ˆ í•¨\n")
				}
			}
			VoteMutex.Unlock()
		}
	}()
}

func requestDeviceAddress(producer sarama.SyncProducer, deviceId string) error { // ì£¼ì†Œ ìš”ì²­ í•¨ìˆ˜
	msg := types.DeviceToAddressMessage{
		DeviceID: deviceId,
		SenderID: config.FullnodeID,
	}
	bytes, err := json.Marshal(msg)
	if err != nil {
		return err
	}

	kafkaMsg := &sarama.ProducerMessage{
		Topic: config.TopicDeviceToAddressRequest,
		Value: sarama.ByteEncoder(bytes),
	}
	_, _, err = producer.SendMessage(kafkaMsg)
	return err
}

var deviceAddressMap = sync.Map{} // deviceId â†’ address

func StartDeviceAddressConsumer() {
	brokers := config.KafkaBrokers
	topic := config.TopicDeviceToAddress
	partition := int32(0)

	cfg := sarama.NewConfig()
	cfg.Version = sarama.V2_1_0_0

	consumer, err := sarama.NewConsumer(brokers, cfg)
	if err != nil {
		panic(fmt.Sprintf("[Kafka: DeviceAddress] Consumer ìƒì„± ì‹¤íŒ¨: %v", err))
	}

	partitionConsumer, err := consumer.ConsumePartition(topic, partition, sarama.OffsetNewest)
	if err != nil {
		panic(fmt.Sprintf("[Kafka: DeviceAddress] íŒŒí‹°ì…˜ êµ¬ë… ì‹¤íŒ¨: %v", err))
	}

	fmt.Println("[Kafka: DeviceAddress] Consumer ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")

	go func() {
		for msg := range partitionConsumer.Messages() {
			fmt.Printf("[Kafka: DeviceAddress] ë©”ì‹œì§€ ìˆ˜ì‹  (offset=%d, partition=%d): %s\n",
				msg.Offset, msg.Partition, string(msg.Value))

			var response types.DeviceToAddressMessage
			if err := json.Unmarshal(msg.Value, &response); err != nil {
				fmt.Printf("[Kafka: DeviceAddress] JSON íŒŒì‹± ì‹¤íŒ¨: %v\n", err)
				continue
			}

			// ë‚´ ë…¸ë“œê°€ ë³´ë‚¸ ë©”ì‹œì§€ë§Œ ì²˜ë¦¬
			if response.SenderID != config.FullnodeID {
				continue // ë‹¤ë¥¸ ë…¸ë“œì˜ ì‘ë‹µ â†’ ë¬´ì‹œ
			}

			if response.DeviceID == "" {
				fmt.Printf("âš ï¸ [Kafka: DeviceAddress] device_id ì—†ìŒ. ë¬´ì‹œë¨: %v\n", response)
				continue
			}
			if response.Address == "" {
				fmt.Printf("âš ï¸ [Kafka: DeviceAddress] address ë¹„ì–´ ìˆìŒ. device_id=%s\n", response.DeviceID)
			}

			// ì¤‘ë³µ í™•ì¸
			if val, ok := deviceAddressMap.Load(response.DeviceID); ok {
				fmt.Printf("[Kafka: DeviceAddress] ê¸°ì¡´ ê°’ ë®ì–´ì”€: %s â†’ %s (ê¸°ì¡´=%s)\n",
					response.DeviceID, response.Address, val.(string))
			} else {
				fmt.Printf("[Kafka: DeviceAddress] ì €ì¥ë¨: %s â†’ %s\n", response.DeviceID, response.Address)
			}

			deviceAddressMap.Store(response.DeviceID, response.Address)
		}
	}()
}

func StartLocationOutputConsumer() {
	brokers := config.KafkaBrokers
	topic := config.TopicLocationResult
	partition := int32(0)

	cfg := sarama.NewConfig()
	cfg.Version = sarama.V2_1_0_0

	// âœ… ë‹¨ì¼ Consumer ìƒì„± (ConsumerGroup âŒ)
	consumer, err := sarama.NewConsumer(brokers, cfg)
	if err != nil {
		panic(fmt.Sprintf("[Kafka: Location] ë‹¨ì¼ Consumer ìƒì„± ì‹¤íŒ¨: %v", err))
	}

	// âœ… íŒŒí‹°ì…˜ ì§ì ‘ êµ¬ë…
	partitionConsumer, err := consumer.ConsumePartition(topic, partition, sarama.OffsetNewest)
	if err != nil {
		panic(fmt.Sprintf("[Kafka: Location] íŒŒí‹°ì…˜ êµ¬ë… ì‹¤íŒ¨: %v", err))
	}

	// âœ… ë©”ì‹œì§€ ìˆ˜ì‹  ë£¨í”„
	go func() {
		fmt.Println("[Kafka: Location] ì‘ë‹µ ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")
		for msg := range partitionConsumer.Messages() {
			fmt.Println("[Kafka: Location] ìˆ˜ì‹ ëœ ë©”ì‹œì§€:", string(msg.Value))

			var outputMsg LocationOutputMessage
			if err := json.Unmarshal(msg.Value, &outputMsg); err != nil {
				fmt.Println("[Kafka: Location] ë©”ì‹œì§€ íŒŒì‹± ì‹¤íŒ¨:", err)
				continue
			}

			// âš ï¸ í•„í„°ë§: ë‚´ ë…¸ë“œê°€ ë³´ë‚¸ ë©”ì‹œì§€ì¸ì§€ í™•ì¸ (ì„ íƒì ìœ¼ë¡œ ì¶”ê°€)
			if outputMsg.SenderID != config.FullnodeID {
				fmt.Printf("[Kafka: Location] id: %s\n", outputMsg.SenderID)
				continue // ë‚´ ì‘ë‹µ ì•„ë‹˜, ë¬´ì‹œ
			}

			RewardWeight[outputMsg.Hash] = outputMsg.Output
			// âœ… ì²˜ë¦¬ ë¡œì§
			fmt.Printf("[Kafka: Location] í•´ì‹œ: %s, ë³´ìƒ ê°€ì¤‘ì¹˜: %f\n", outputMsg.Hash, RewardWeight[outputMsg.Hash])

		}
	}()
}

func StartSolarKafkaConsumer() {
	brokers := config.KafkaBrokers
	topic := config.TopicLightTx
	groupID := config.TopicLightTxGroup // ëª¨ë“  ì„œë²„ì—ì„œ ë™ì¼í•˜ê²Œ ì„¤ì •í•´ì•¼ í•¨

	saramaConfig := sarama.NewConfig()
	saramaConfig.Version = sarama.V2_1_0_0
	saramaConfig.Consumer.Return.Errors = true
	saramaConfig.Consumer.Offsets.Initial = sarama.OffsetNewest

	consumerGroup, err := sarama.NewConsumerGroup(brokers, groupID, saramaConfig)
	InitDeviceProducer()
	if err != nil {
		panic(fmt.Sprintf("[Kafka: Solar data] ConsumerGroup ìƒì„± ì‹¤íŒ¨: %v", err))
	}

	go func() {
		for {
			err := consumerGroup.Consume(context.Background(), []string{topic}, &lightTxHandler{})
			if err != nil {
				fmt.Printf("[Kafka: Solar data] Consume ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %v\n", err)
			}
		}
	}()

	fmt.Println("[Kafka: Solar data] Kafka Consumer Group ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")
	VoteEvaluator() // ì°¸ì—¬ì ìˆ˜ì§‘ + í‰ê°€ ë£¨í‹´ ì‹œì‘
}

func StartConsumer() {
	go StartSolarKafkaConsumer()     // íƒœì–‘ê´‘ ë°œì „ëŸ‰ í† í”½
	go StartAccountConsumer()        // íšŒì›ê°€ì… ìš”ì²­ í† í”½
	go StartVoteMemberConsumer()     // íšŒì› ìˆ˜ í† í”½
	go StartDeviceAddressConsumer()  // ë””ë°”ì´ìŠ¤ id, ì£¼ì†Œ ë§¤í•‘ í† í”½
	go StartLocationOutputConsumer() // ìœ„ì¹˜ ì •ë³´ í† í”½
}
