package consumer

import (
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"log"
	"strconv"
	"sync"
	"time"

	"github.com/cosmos/cosmos-sdk/fullnode_bridge/tx"
	"github.com/cosmos/cosmos-sdk/fullnode_bridge/types"

	"github.com/cosmos/cosmos-sdk/fullnode_bridge/config"

	"github.com/IBM/sarama"

	"crypto/sha256"

	"github.com/btcsuite/btcutil/bech32"
	"golang.org/x/crypto/ripemd160"
)

type lightTxHandler struct{}

type SignatureEntry struct {
	TxMsg     types.LightTxMessage
	Address   string
	Timestamp time.Time
}

var (
	VoteMap   = make(map[string][]SignatureEntry) // hash -> ì„œëª…ì ëª©ë¡
	DeviceID  = make(map[string]string)           // hash -> device_id
	VoteMutex sync.Mutex
)

var (
	VoteMemberCount int // ë°ì´í„°ë² ì´ìŠ¤ ë©¤ë²„ ìˆ˜ ê¸°ë¡ ë³€ìˆ˜
)

type VoteMemberMsg struct {
	Count int `json:"count"`
}

var KafkaProducerDevice sarama.SyncProducer // ë””ë°”ì´ìŠ¤ ì •ë³´ ì „ì†¡ í”„ë¡œë“€ì„œ

func InitDeviceProducer() {
	KafkaProducerDevice = NewKafkaSyncProducer(config.KafkaBrokers)
}

func NewKafkaSyncProducer(brokers []string) sarama.SyncProducer { // í”„ë¡œë“€ì„œ ì´ˆê¸°í™”
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll // ëª¨ë“  ISRì— ack ë°›ì„ ë•Œê¹Œì§€ ëŒ€ê¸°
	config.Producer.Retry.Max = 5                    // ì¬ì‹œë„ íšŸìˆ˜
	config.Producer.Return.Successes = true          // ì„±ê³µ ê²°ê³¼ ìˆ˜ì‹  ì„¤ì •

	producer, err := sarama.NewSyncProducer(brokers, config)
	if err != nil {
		log.Fatalf("Kafka í”„ë¡œë“€ì„œ ìƒì„± ì‹¤íŒ¨: %v", err)
	}
	return producer
}

func (h *lightTxHandler) Setup(_ sarama.ConsumerGroupSession) error   { return nil }
func (h *lightTxHandler) Cleanup(_ sarama.ConsumerGroupSession) error { return nil }

func (h *lightTxHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error { // íƒœì–‘ê´‘ ë°ì´í„° ìˆ˜ì‹  ì²˜ë¦¬
	for msg := range claim.Messages() {
		fmt.Println("[Kafka: Solar data][Raw Message]:", string(msg.Value)) // ğŸ‘‰ ìˆ˜ì‹ ëœ ì›ë³¸ ë©”ì‹œì§€ ì¶œë ¥

		var txMsg types.LightTxMessage
		if err := json.Unmarshal(msg.Value, &txMsg); err != nil {
			fmt.Println("[Kafka: Solar data] ë©”ì‹œì§€ íŒŒì‹± ì‹¤íŒ¨:", err)
			continue
		}

		for len(txMsg.Pubkey)%4 != 0 {
			txMsg.Pubkey += "="
		}
		pubkeyBytes, err := base64.StdEncoding.DecodeString(txMsg.Pubkey)
		if err != nil {
			fmt.Println("[Kafka: Solar data] í¼ë¸”ë¦­í‚¤ ë””ì½”ë”© ì‹¤íŒ¨:", err)
			continue
		}

		if len(pubkeyBytes) != 33 {
			fmt.Println("[Kafka: Solar data] ì˜ëª»ëœ í¼ë¸”ë¦­í‚¤ ê¸¸ì´:", len(pubkeyBytes))
			continue
		}

		address, err := PubKeyToAddress(pubkeyBytes)
		if err != nil {
			fmt.Println("[Kafka: Solar data] ì£¼ì†Œ ìƒì„± ì‹¤íŒ¨:", err)
			continue
		}
		VoteMutex.Lock()
		VoteMap[txMsg.Hash] = append(VoteMap[txMsg.Hash], SignatureEntry{
			TxMsg:     txMsg,
			Address:   address,
			Timestamp: time.Now(),
		})
		// í•´ì‹œë³„ë¡œ device_id ë˜ëŠ” facility_id ì €ì¥

		if txMsg.Original != nil && txMsg.Original.DeviceID != "" {
			DeviceID[txMsg.Hash] = txMsg.Original.DeviceID
		} else if txMsg.REC != nil && txMsg.REC.FacilityID != "" {
			DeviceID[txMsg.Hash] = txMsg.REC.FacilityID
		} else {
			fmt.Println("[Kafka: Solar data] DeviceIDì™€ FacilityID ëª¨ë‘ ì¡´ì¬í•˜ì§€ ì•ŠìŒ, ì €ì¥ ì•ˆ í•¨:", txMsg.Hash)
		}
		VoteMutex.Unlock()

		session.MarkMessage(msg, "")
	}
	return nil
}

func PubKeyToAddress(pubKeyBytes []byte) (string, error) { // ì£¼ì†Œ ë³€í™˜ í•¨ìˆ˜
	// 1. SHA-256
	sha := sha256.Sum256(pubKeyBytes)

	// 2. RIPEMD-160
	ripemd := ripemd160.New()
	_, err := ripemd.Write(sha[:])
	if err != nil {
		return "", err
	}
	pubKeyHash := ripemd.Sum(nil) // 20ë°”ì´íŠ¸

	// 3. Bech32 ì¸ì½”ë”©
	converted, err := bech32.ConvertBits(pubKeyHash, 8, 5, true)
	if err != nil {
		return "", err
	}
	address, err := bech32.Encode("cosmos", converted)
	if err != nil {
		return "", err
	}

	return address, nil
}

func StartVoteEvaluator() { // íˆ¬í‘œ ìˆ˜ì§‘ ë°˜ë³µ í•¨ìˆ˜
	fmt.Println("[Kafka: Solar data] StartVoteEvaluator ì‹œì‘ë¨")

	ticker := time.NewTicker(10 * time.Second)
	go func() {
		for range ticker.C {
			now := time.Now()
			fmt.Println("[Kafka: Solar data] íˆ¬í‘œ ìˆ˜ì§‘ ì‹œì‘:", now.Format(time.RFC3339))

			VoteMutex.Lock()
			for hash, entries := range VoteMap {
				if len(entries) == 0 {
					fmt.Printf("[Kafka: Solar data] Tx: [%s] entries ì—†ìŒ. ê±´ë„ˆëœ€\n", hash)
					continue
				}

				elapsed := now.Sub(entries[0].Timestamp)
				fmt.Printf("[Kafka: Solar data]  [%s] entry ìˆ˜: %d, ê²½ê³¼ì‹œê°„: %.1fì´ˆ\n", hash, len(entries), elapsed.Seconds())

				if elapsed < 10*time.Second {
					fmt.Printf("[Kafka: Solar data] (%.1fì´ˆ ê²½ê³¼). íˆ¬í‘œ ê²€ì¦ ì¤‘\n", elapsed.Seconds())
					continue
				}

				// ì£¼ì†Œ ì¤‘ë³µ ì œê±°
				unique := map[string]bool{}
				for _, e := range entries {
					unique[e.Address] = true
				}
				var uniqueList []string
				for k := range unique {
					uniqueList = append(uniqueList, k)
				}

				if len(unique) >= 1 {
					// if len(unique) >= VoteMemberCount/2 {
					txMsg := entries[0].TxMsg
					fmt.Println("[Kafka: Solar data] íŠ¸ëœì­ì…˜ ì „ì†¡ ì‹œë„ ì¤‘...")

					txHash, err := tx.BroadcastLightTx(txMsg)
					if err != nil {
						fmt.Println("[Kafka: Solar data] íŠ¸ëœì­ì…˜ ì „ì†¡ ì‹¤íŒ¨:", err)
					} else {
						fmt.Printf("[Kafka: Solar data] íŠ¸ëœì­ì…˜ ì „ì†¡ ì„±ê³µ: %s\n", txHash)
						fmt.Printf("[Kafka: Solar data] â†’ ì„œëª…ì ì£¼ì†Œ ëª©ë¡: %v\n", uniqueList)

						deviceId := DeviceID[hash]
						if err := requestDeviceAddress(KafkaProducerDevice, deviceId); err != nil {
							fmt.Println("ì£¼ì†Œ ìš”ì²­ ì‹¤íŒ¨:", err)
						} else {
							// ì¼ì • ì‹œê°„ ëŒ€ê¸° (ìµœëŒ€ 1ì´ˆ)
							var userAddress string
							for i := 0; i < 20; i++ {
								if val, ok := deviceAddressMap.Load(deviceId); ok {
									userAddress = val.(string)
									break
								}
								time.Sleep(100 * time.Millisecond)
							}

							if txMsg.Original != nil {
								// ğŸŒ SolarData ê¸°ë°˜ ë³´ìƒ
								tx.SendRewardTx(userAddress, txMsg.Original.TotalEnergy)
							} else if txMsg.REC != nil {
								// REC ê¸°ë°˜ ë³´ìƒ: ì¸¡ì •ëŸ‰ MWhë¥¼ float64ë¡œ ë³€í™˜ í›„ ë³´ìƒ
								mwhStr := txMsg.REC.MeasuredVolumeMWh
								mwh, err := strconv.ParseFloat(mwhStr, 64)
								if err != nil {
									fmt.Printf("[Kafka: Solar data] REC ë°œì „ëŸ‰ íŒŒì‹± ì‹¤íŒ¨: %v\n", err)
								} else {
									// MWh â†’ Wh ë³€í™˜ (1 MWh = 1,000,000 Wh)
									tx.SendRewardTx(userAddress, mwh*1000000)
								}
							} else {
								fmt.Println("[Kafka: Solar data] ë³´ìƒí•  ë°ì´í„° ì—†ìŒ (Original, REC ëª¨ë‘ nil)")
							}
						}
					}

					delete(VoteMap, hash)
					fmt.Printf("[Kafka: Solar data] [%s] voteMapì—ì„œ ì œê±°ë¨\n", hash)
				} else {
					fmt.Printf("[Kafka: Solar data] ê³ ìœ  ì£¼ì†Œ ì—†ìŒ. íŠ¸ëœì­ì…˜ ì „ì†¡ ì•ˆ í•¨\n")
				}
			}
			VoteMutex.Unlock()
		}
	}()
}

func requestDeviceAddress(producer sarama.SyncProducer, deviceId string) error { // ì£¼ì†Œ ìš”ì²­ í•¨ìˆ˜
	msg := types.DeviceToAddressMessage{
		DeviceID: deviceId,
	}
	bytes, err := json.Marshal(msg)
	if err != nil {
		return err
	}

	kafkaMsg := &sarama.ProducerMessage{
		Topic: config.TopicDeviceToAddressRequest,
		Value: sarama.ByteEncoder(bytes),
	}
	_, _, err = producer.SendMessage(kafkaMsg)
	return err
}

var deviceAddressMap = sync.Map{} // deviceId â†’ address

func StartDeviceAddressConsumer() { // ì£¼ì†Œ ìˆ˜ì‹  í•¨ìˆ˜
	consumerGroup, err := sarama.NewConsumerGroup(config.KafkaBrokers, config.TopicDeviceToAddressGroup, nil)
	if err != nil {
		panic(fmt.Sprintf("DeviceAddressConsumerGroup ìƒì„± ì‹¤íŒ¨: %v", err))
	}
	fmt.Println("[Kafka: Device to Address] Kafka Consumer Group ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")
	go func() {
		for {
			err := consumerGroup.Consume(context.Background(), []string{config.TopicDeviceToAddress}, &deviceAddressHandler{})
			if err != nil {
				fmt.Printf("DeviceAddress Consume ì˜¤ë¥˜: %v\n", err)
			}
		}
	}()
}

type deviceAddressHandler struct{}

func (h *deviceAddressHandler) Setup(sarama.ConsumerGroupSession) error   { return nil }
func (h *deviceAddressHandler) Cleanup(sarama.ConsumerGroupSession) error { return nil }
func (h *deviceAddressHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	for msg := range claim.Messages() {
		fmt.Printf("[Kafka: DeviceAddress] ë©”ì‹œì§€ ìˆ˜ì‹  (offset=%d, partition=%d): %s\n",
			msg.Offset, msg.Partition, string(msg.Value))

		var response types.DeviceToAddressMessage
		if err := json.Unmarshal(msg.Value, &response); err != nil {
			fmt.Printf("[Kafka: DeviceAddress] JSON íŒŒì‹± ì‹¤íŒ¨: %v\n", err)
			continue
		}

		if response.DeviceID == "" {
			fmt.Printf("âš ï¸ [Kafka: DeviceAddress] device_id ì—†ìŒ. ë¬´ì‹œë¨: %v\n", response)
			continue
		}

		if response.Address == "" {
			fmt.Printf("âš ï¸ [Kafka: DeviceAddress] address ë¹„ì–´ ìˆìŒ. device_id=%s\n", response.DeviceID)
		}

		// ì¤‘ë³µ í™•ì¸
		if val, ok := deviceAddressMap.Load(response.DeviceID); ok {
			fmt.Printf("[Kafka: DeviceAddress] ê¸°ì¡´ ê°’ ë®ì–´ì”€: %s â†’ %s (ê¸°ì¡´=%s)\n",
				response.DeviceID, response.Address, val.(string))
		} else {
			fmt.Printf("[Kafka: DeviceAddress] ì €ì¥ë¨: %s â†’ %s\n", response.DeviceID, response.Address)
		}

		deviceAddressMap.Store(response.DeviceID, response.Address)
		session.MarkMessage(msg, "")
	}
	return nil
}

func StartSolarKafkaConsumer() {
	brokers := config.KafkaBrokers
	topic := config.TopicLightTx
	groupID := config.TopicLightTxGroup // ëª¨ë“  ì„œë²„ì—ì„œ ë™ì¼í•˜ê²Œ ì„¤ì •í•´ì•¼ í•¨

	saramaConfig := sarama.NewConfig()
	saramaConfig.Version = sarama.V2_1_0_0
	saramaConfig.Consumer.Return.Errors = true
	saramaConfig.Consumer.Offsets.Initial = sarama.OffsetNewest

	consumerGroup, err := sarama.NewConsumerGroup(brokers, groupID, saramaConfig)
	InitDeviceProducer()
	if err != nil {
		panic(fmt.Sprintf("[Kafka: Solar data] ConsumerGroup ìƒì„± ì‹¤íŒ¨: %v", err))
	}

	go func() {
		for {
			err := consumerGroup.Consume(context.Background(), []string{topic}, &lightTxHandler{})
			if err != nil {
				fmt.Printf("[Kafka: Solar data] Consume ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %v\n", err)
			}
		}
	}()

	fmt.Println("[Kafka: Solar data] Kafka Consumer Group ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")
	StartVoteEvaluator() // ì°¸ì—¬ì ìˆ˜ì§‘ + í‰ê°€ ë£¨í‹´ ì‹œì‘
}

func StartVoteMemberConsumer() {
	fmt.Println("[Kafka: Users] StartVoteMemberConsumer ì‹œì‘ë¨")

	brokers := config.KafkaBrokers
	topic := config.TopicVoteMember
	partition := int32(0)

	saramaConfig := sarama.NewConfig()
	saramaConfig.Version = sarama.V2_1_0_0

	// 1. ë©”ì‹œì§€ ìš”ì²­ì„ ë¨¼ì € ì „ì†¡
	go func() {
		err := sendInitialRequest(brokers, config.TopicRequestMemberCount)
		if err != nil {
			fmt.Printf("[Kafka: Users] ì´ˆê¸° ìš”ì²­ ì „ì†¡ ì‹¤íŒ¨: %v\n", err)
		} else {
			fmt.Println("[Kafka: Users] ì´ˆê¸° VoteMemberCount ìš”ì²­ ì „ì†¡ ì™„ë£Œ")
		}
	}()

	// 2. ì»¨ìŠˆë¨¸ ì´ˆê¸°í™”
	consumer, err := sarama.NewConsumer(brokers, saramaConfig)
	if err != nil {
		panic(fmt.Sprintf("[Kafka: Users] Consumer ìƒì„± ì‹¤íŒ¨: %v", err))
	}

	partitionConsumer, err := consumer.ConsumePartition(topic, partition, sarama.OffsetNewest)
	if err != nil {
		panic(fmt.Sprintf("[Kafka: Users] íŒŒí‹°ì…˜ êµ¬ë… ì‹¤íŒ¨: %v", err))
	}

	go func() {
		fmt.Println("[Kafka: Users] Kafka Partition Consumer ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")
		for msg := range partitionConsumer.Messages() {
			fmt.Printf("[Kafka: Users] ìˆ˜ì‹  ë©”ì‹œì§€: %s\n", string(msg.Value))

			var parsed VoteMemberMsg
			if err := json.Unmarshal(msg.Value, &parsed); err != nil {
				fmt.Printf("[Kafka: Users] JSON íŒŒì‹± ì˜¤ë¥˜: %v\n", err)
				continue
			}

			VoteMemberCount = parsed.Count
			fmt.Printf("[Kafka: Users] VoteMemberCount ê°±ì‹ ë¨: %d\n", VoteMemberCount)
		}
	}()
}

func sendInitialRequest(brokers []string, topic string) error {
	producer, err := sarama.NewSyncProducer(brokers, nil)
	if err != nil {
		return fmt.Errorf("Kafka í”„ë¡œë“€ì„œ ìƒì„± ì‹¤íŒ¨: %w", err)
	}
	defer producer.Close()

	// ë©”ì‹œì§€ ë‚´ìš©ì´ ì—†ì–´ë„ OK. ìˆ˜ì‹ ì(ì˜¤ë¼í´)ëŠ” topicë§Œ ë³´ë©´ ë¨
	msg := &sarama.ProducerMessage{
		Topic: topic,
		Value: sarama.StringEncoder(`{"request": "latest_vote_count"}`),
	}

	_, _, err = producer.SendMessage(msg)
	return err
}
